{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Corpus inicial\n",
        "raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4}\n",
        "\n",
        "# Convertir palabras en caracteres separados por espacios\n",
        "token_freqs = {}\n",
        "for token, freq in raw_token_freqs.items():\n",
        "    token_freqs[' '.join(list(token))] = freq\n",
        "\n",
        "# Función para encontrar el par más frecuente\n",
        "def get_max_freq_pair(token_freqs):\n",
        "    pairs = collections.defaultdict(int)\n",
        "    for token, freq in token_freqs.items():\n",
        "        symbols = token.split()\n",
        "        for i in range(len(symbols) - 1):\n",
        "            pairs[symbols[i], symbols[i + 1]] += freq\n",
        "    return max(pairs, key=pairs.get)\n",
        "\n",
        "# Función para fusionar el par más frecuente\n",
        "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
        "    symbols.append(''.join(max_freq_pair))\n",
        "    new_token_freqs = {}\n",
        "    for token, freq in token_freqs.items():\n",
        "        new_token = token.replace(' '.join(max_freq_pair), ''.join(max_freq_pair))\n",
        "        new_token_freqs[new_token] = freq\n",
        "    return new_token_freqs\n",
        "\n",
        "# Inicializar vocabulario y ejecutar BPE paso a paso\n",
        "symbols = list(\"abcdefghijklmnopqrstuvwxyz_\")\n",
        "num_merges = 10  # Número de fusiones deseadas\n",
        "\n",
        "print(\"=== Proceso de Byte Pair Encoding ===\\n\")\n",
        "for i in range(num_merges):\n",
        "    print(f\"\\nIteración {i + 1}:\")\n",
        "    print(f\"Corpus actual: {token_freqs}\")\n",
        "    max_freq_pair = get_max_freq_pair(token_freqs)\n",
        "    print(f\"Par más frecuente: {max_freq_pair}\")\n",
        "    token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols)\n",
        "    print(f\"Nuevo corpus: {token_freqs}\")\n",
        "    print(f\"Vocabulario aprendido: {symbols}\")\n",
        "\n",
        "print(\"\\n=== Resultado final ===\")\n",
        "print(\"Corpus segmentado:\", token_freqs)\n",
        "print(\"Vocabulario aprendido:\", symbols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsK-jrqaJhrz",
        "outputId": "e43e7170-456d-49f1-d617-c8d9f99fe44d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Proceso de Byte Pair Encoding ===\n",
            "\n",
            "\n",
            "Iteración 1:\n",
            "Corpus actual: {'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}\n",
            "Par más frecuente: ('t', 'a')\n",
            "Nuevo corpus: {'f a s t _': 4, 'f a s t e r _': 3, 'ta l l _': 5, 'ta l l e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta']\n",
            "\n",
            "Iteración 2:\n",
            "Corpus actual: {'f a s t _': 4, 'f a s t e r _': 3, 'ta l l _': 5, 'ta l l e r _': 4}\n",
            "Par más frecuente: ('ta', 'l')\n",
            "Nuevo corpus: {'f a s t _': 4, 'f a s t e r _': 3, 'tal l _': 5, 'tal l e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal']\n",
            "\n",
            "Iteración 3:\n",
            "Corpus actual: {'f a s t _': 4, 'f a s t e r _': 3, 'tal l _': 5, 'tal l e r _': 4}\n",
            "Par más frecuente: ('tal', 'l')\n",
            "Nuevo corpus: {'f a s t _': 4, 'f a s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall']\n",
            "\n",
            "Iteración 4:\n",
            "Corpus actual: {'f a s t _': 4, 'f a s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Par más frecuente: ('f', 'a')\n",
            "Nuevo corpus: {'fa s t _': 4, 'fa s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa']\n",
            "\n",
            "Iteración 5:\n",
            "Corpus actual: {'fa s t _': 4, 'fa s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Par más frecuente: ('fa', 's')\n",
            "Nuevo corpus: {'fas t _': 4, 'fas t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas']\n",
            "\n",
            "Iteración 6:\n",
            "Corpus actual: {'fas t _': 4, 'fas t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Par más frecuente: ('fas', 't')\n",
            "Nuevo corpus: {'fast _': 4, 'fast e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast']\n",
            "\n",
            "Iteración 7:\n",
            "Corpus actual: {'fast _': 4, 'fast e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
            "Par más frecuente: ('e', 'r')\n",
            "Nuevo corpus: {'fast _': 4, 'fast er _': 3, 'tall _': 5, 'tall er _': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er']\n",
            "\n",
            "Iteración 8:\n",
            "Corpus actual: {'fast _': 4, 'fast er _': 3, 'tall _': 5, 'tall er _': 4}\n",
            "Par más frecuente: ('er', '_')\n",
            "Nuevo corpus: {'fast _': 4, 'fast er_': 3, 'tall _': 5, 'tall er_': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_']\n",
            "\n",
            "Iteración 9:\n",
            "Corpus actual: {'fast _': 4, 'fast er_': 3, 'tall _': 5, 'tall er_': 4}\n",
            "Par más frecuente: ('tall', '_')\n",
            "Nuevo corpus: {'fast _': 4, 'fast er_': 3, 'tall_': 5, 'tall er_': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_']\n",
            "\n",
            "Iteración 10:\n",
            "Corpus actual: {'fast _': 4, 'fast er_': 3, 'tall_': 5, 'tall er_': 4}\n",
            "Par más frecuente: ('fast', '_')\n",
            "Nuevo corpus: {'fast_': 4, 'fast er_': 3, 'tall_': 5, 'tall er_': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n",
            "\n",
            "=== Resultado final ===\n",
            "Corpus segmentado: {'fast_': 4, 'fast er_': 3, 'tall_': 5, 'tall er_': 4}\n",
            "Vocabulario aprendido: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n"
          ]
        }
      ]
    }
  ]
}